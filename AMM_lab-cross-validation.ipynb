{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1df8cc01-551c-4ba4-b4e2-fceb26e849d6",
   "metadata": {},
   "source": [
    "**<font size=\"5\"> Lab Cross Validationr </font>**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99605565-39dd-4b44-bf6d-2b393cc48a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "643342d3-f540-471e-9f8c-c1e6f48f9511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (5625, 4)\n",
      "X_test shape: (1407, 4)\n"
     ]
    }
   ],
   "source": [
    "churnData = pd.read_csv('Customer-Churn.csv')\n",
    "churnData['TotalCharges'] = pd.to_numeric(churnData['TotalCharges'], errors='coerce')\n",
    "churnData.dropna(inplace=True)\n",
    "features = ['tenure', 'SeniorCitizen', 'MonthlyCharges', 'TotalCharges']\n",
    "X = churnData[features]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y = churnData['Churn']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0674843e-9665-4248-854e-9d2a9fc39ed5",
   "metadata": {},
   "source": [
    "**Apply SMOTE for upsampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a298f7e9-596b-4f73-9751-fe926c6941e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_smote shape: (8260, 4)\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"X_smote shape:\", X_smote.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb921479-4f47-4bd4-ad07-42fec8fd6ab7",
   "metadata": {},
   "source": [
    "The result \"X_smote shape: (8260, 4)\" means that after applying a technique called SMOTE (which helps balance our data for better predictions), we now have a dataset with 8,260 rows and 4 columns. Each row represents a customer, and these 8,260 customers have 4 different characteristics or features that we're using to make predictions about whether they will leave the service or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fd79d61-6064-426f-8e93-cd4d3299b044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Mean Accuracy (SMOTE): 0.7317191283292978\n",
      "Decision Tree Mean Accuracy (SMOTE): 0.7616222760290556\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression()\n",
    "decision_tree_model = DecisionTreeClassifier()\n",
    "\n",
    "logistic_scores = cross_val_score(logistic_model, X_smote, y_smote, cv=5, scoring='accuracy')\n",
    "decision_tree_scores = cross_val_score(decision_tree_model, X_smote, y_smote, cv=5, scoring='accuracy')\n",
    "\n",
    "\n",
    "logistic_mean_accuracy = logistic_scores.mean()\n",
    "decision_tree_mean_accuracy = decision_tree_scores.mean()\n",
    "\n",
    "print(\"Logistic Regression Mean Accuracy (SMOTE):\", logistic_mean_accuracy)\n",
    "print(\"Decision Tree Mean Accuracy (SMOTE):\", decision_tree_mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2495d73-154b-4476-9671-2476182c5836",
   "metadata": {},
   "source": [
    "These results represent the accuracy of two different models in making predictions about whether customers will leave a service or not. Here's a simple explanation:\n",
    "\n",
    "**Logistic Regression Mean Accuracy (SMOTE):** 73.2% - This means that, on average, the logistic regression model correctly predicts whether a customer will leave or stay in the service about 73.2% of the time when we used a technique called SMOTE to balance the data.\n",
    "\n",
    "**Decision Tree Mean Accuracy (SMOTE):** 76.2% - Similarly, the decision tree model correctly predicts about 76.2% of the time using the same balanced data.\n",
    "\n",
    "In simple terms, both models are doing a decent job of predicting customer behavior, with the decision tree model being slightly more accurate in this case. These accuracies give us an idea of how well these models perform, and higher accuracy is generally better, although other factors may also be important when choosing the best model for a specific problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12c37c44-2b6c-46a1-bb8e-24538802613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tomek_links = TomekLinks()\n",
    "X_tomek, y_tomek = tomek_links.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38ee51f-16e6-4daa-bb91-c5837d39dcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tomek shape: (5224, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_tomek shape:\", X_tomek.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5103f0aa-81e4-4351-a07c-43566765331f",
   "metadata": {},
   "source": [
    "The result **\"X_tomek shape: (5224, 4)\"** means that after applying a technique called TomekLinks (which helps reduce data imbalance), we now have a dataset with 5,224 rows and 4 columns. Each row represents a customer, and these 5,224 customers have 4 different characteristics or features that we're using to make predictions about whether they will leave the service or not. This smaller dataset is a result of the downsampling process used to balance the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5f4716a-8309-4173-88f8-d319f4497eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model_tomek = LogisticRegression()\n",
    "decision_tree_model_tomek = DecisionTreeClassifier()\n",
    "\n",
    "logistic_scores_tomek = cross_val_score(logistic_model_tomek, X_tomek, y_tomek, cv=5, scoring='accuracy')\n",
    "decision_tree_scores_tomek = cross_val_score(decision_tree_model_tomek, X_tomek, y_tomek, cv=5, scoring='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36465c01-5d29-48fd-bf11-e942c3436f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_mean_accuracy_tomek = logistic_scores_tomek.mean()\n",
    "decision_tree_mean_accuracy_tomek = decision_tree_scores_tomek.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba46fd4b-808d-48e9-a72e-6b0b64ababac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Mean Accuracy (TomekLinks): 0.7934554253973493\n",
      "Decision Tree Mean Accuracy (TomekLinks): 0.7530655007424516\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Mean Accuracy (TomekLinks):\", logistic_mean_accuracy_tomek)\n",
    "print(\"Decision Tree Mean Accuracy (TomekLinks):\", decision_tree_mean_accuracy_tomek)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f9b040-1236-4b7b-b14d-a0a81b10d86c",
   "metadata": {},
   "source": [
    "These results represent the accuracy of two different models in making predictions about whether customers will leave a service or not, after applying a technique called TomekLinks to reduce data imbalance. Here's a simple explanation:\n",
    "\n",
    "**Logistic Regression Mean Accuracy (TomekLinks):** 79.3% - This means that, on average, the logistic regression model correctly predicts whether a customer will leave or stay in the service about 79.3% of the time when we used TomekLinks to balance the data.\n",
    "\n",
    "**Decision Tree Mean Accuracy (TomekLinks):** 75.3% - Similarly, the decision tree model correctly predicts about 75.3% of the time using the same balanced data with TomekLinks.\n",
    "\n",
    "In simple terms, both models are doing a good job of predicting customer behavior, with the logistic regression model being slightly more accurate in this case. These accuracies give us an idea of how well these models perform after balancing the data, and higher accuracy is generally better, although other factors may also be important when choosing the best model for a specific problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e00d651-4107-4a4a-9200-8e0ad7d4afdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution after TomekLinks:\n",
      " Churn\n",
      "No     3729\n",
      "Yes    1495\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Class Distribution after TomekLinks:\\n\", y_tomek.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a359e-dbfe-4e92-9767-fd2111c4f4f6",
   "metadata": {},
   "source": [
    "**Class Distribution after TomekLinks:**\n",
    "\n",
    "After applying a TomekLinks to the data, we now have a more balanced class distribution:\n",
    "\n",
    "**No**: There are 3,729 customers who haven't left the service.\n",
    "**Yes**: There are 1,495 customers who have left the service.\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "By using TomekLinks, we made our dataset more balanced, which helped improve the accuracy of our models. The logistic regression model achieved an accuracy of **79.3%**, and the decision tree model achieved an accuracy of **75.3%** in predicting whether customers will leave the service. This shows that with balanced data, our models are better at making predictions, particularly the logistic regression model, which performed the best in this case. Balancing the data is an important step in building accurate predictive models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6f148b-0bfb-46a9-926d-41fea159d8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
